{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "import re\n",
    "import numpy as np\n",
    "import collections\n",
    "\n",
    "import nltk\n",
    "import spacy\n",
    "\n",
    "from datetime import datetime\n",
    "from datetime import timedelta\n",
    "\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "from string import punctuation\n",
    "from wordcloud import WordCloud, STOPWORDS\n",
    "\n",
    "from statistics import mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/mario/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "nlp = spacy.load(\"pt_core_news_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "default_hashtags = ['#coronavírus','#covid19','#covid2019','#covid19brasil','#covid2019brasil','#covid','#corona','#coronavirusbrasil', '#coronavirusnobrasil', '#coronavirus', '#covid-19', '#covidー19', '#covid_19', '#novocoronavírus']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Funções gerais"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "## função para geração de nuvens de palavras a partir de uma lista de strings\n",
    "def generate_word_cloud(words_list, lower_case):\n",
    "    \n",
    "    if (len(words_list) > 0):   \n",
    "        words=\"\"\n",
    "\n",
    "        # Criando string a partir das palavras        \n",
    "        for word in words_list:\n",
    "            if (lower_case):\n",
    "                words = words + ' ' + word.lower()\n",
    "            else:\n",
    "                words = words + ' ' + word\n",
    "                 \n",
    "        stopwords = set(STOPWORDS)\n",
    "        stopwords.update(nltk.corpus.stopwords.words('portuguese'))\n",
    "        stopwords.update(['coronavíru','coronaviru','víru','viru','corona','coronavírus','coronavirus','virus','vírus'])\n",
    "        stopwords.update( ['…','``','...','\\'\\'','t','https','http','co','rt','pra','pro','vc','pq','q','contra','tudo',',sobre','aí','outro','tá'])\n",
    "        \n",
    "        wordcloud = WordCloud(stopwords=stopwords, background_color=\"white\").generate(words)\n",
    "\n",
    "        plt.figure(figsize=(8,4))\n",
    "        plt.imshow(wordcloud, interpolation='bilinear')\n",
    "        plt.axis(\"off\")\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função para montar um df de Quantificadores por data a partir do df de Tweets\n",
    "def building_dates_df(df, column):\n",
    "\n",
    "    date_set = set()  \n",
    "    \n",
    "    for item in df.created_at:\n",
    "        date = datetime(item.year, item.month, item.day)\n",
    "        date_set.add(date)\n",
    "    \n",
    "    # Listas utilizadas para montagem do df\n",
    "    date_list = list(date_set)\n",
    "    date_list.sort()\n",
    "    score_mean_list = []\n",
    "        \n",
    "    # Populando quantificadores para cada dia\n",
    "    for index in date_list:\n",
    "        # Média de scores do período\n",
    "        score_mean = mean(df[column].loc[(df['created_at'].dt.year == index.year) & (df['created_at'].dt.month == index.month) & (df['created_at'].dt.day == index.day)])\n",
    "        score_mean_list.append(score_mean)\n",
    "    \n",
    "    # Dicionário utilizado como parâmetro para a montagem\n",
    "    data={'created_at': pd.Series(date_list), column + '_mean':pd.Series(score_mean_list)}\n",
    "    \n",
    "    # Criando df\n",
    "    df = pd.DataFrame(data)\n",
    "    \n",
    "    return df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função para geração de gráficos\n",
    "def generate_graphic(x, y, label, color, xLabel, yLabel, title, start_period, first_case, first_death):\n",
    "    \n",
    "    fig, ax = plt.subplots()\n",
    "\n",
    "    ax.plot(x,y,color=color, linestyle='solid', linewidth=2,label=label)\n",
    "    ax.grid()\n",
    "    ax.margins(0) # remove default margins (matplotlib verision 2+)\n",
    "    \n",
    "    first_case_date = datetime.strptime(first_case, '%Y-%m-%d')\n",
    "    first_death_date = datetime.strptime(first_death, '%Y-%m-%d')\n",
    "    \n",
    "    ax.axvspan(datetime.strptime(start_period, '%Y-%m-%d'), \n",
    "               datetime.strptime(\"2020-05-01\", '%Y-%m-%d'), \n",
    "               fill=True, linewidth=0, color='gainsboro')\n",
    "    \n",
    "    plt.axvline(first_case_date, color='orange')\n",
    "    plt.axvline(first_death_date, color='red')\n",
    "    \n",
    "    plt.rcParams['figure.figsize'] = (18,5)\n",
    "    \n",
    "    plt.xticks(x, rotation=80)\n",
    "    plt.legend(fontsize=15)\n",
    "    plt.xlabel(xLabel,fontsize=15)\n",
    "    plt.ylabel(yLabel,fontsize=15)\n",
    "    plt.title(title)\n",
    "    plt.grid(True, linestyle='--')\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "# Função para geração de gráficos\n",
    "def generate_graphic_cases(x, y, label, color, xLabel, yLabel, title, restriction, first_case, first_death):\n",
    "    \n",
    "    fig, ax = plt.subplots()\n",
    "\n",
    "    ax.plot(x,y,color=color, linestyle='solid', linewidth=2,label=label)\n",
    "    ax.grid()\n",
    "    ax.margins(0) # remove default margins (matplotlib verision 2+)\n",
    "    \n",
    "    first_case_date = datetime.strptime(first_case, '%Y-%m-%d')\n",
    "    first_death_date = datetime.strptime(first_death, '%Y-%m-%d')\n",
    "    \n",
    "    if (restriction != None):\n",
    "        restriction_date = datetime.strptime(restriction, '%Y-%m-%d')\n",
    "        plt.axvline(restriction_date, color='red')\n",
    "    \n",
    "    ax.axvspan(first_case_date, \n",
    "               first_death_date,\n",
    "               fill=True, linewidth=0, color='moccasin')\n",
    "    \n",
    "    ax.axvspan(first_death_date, \n",
    "               datetime.strptime(\"2020-05-01\", '%Y-%m-%d'), \n",
    "               fill=True, linewidth=0, color='gainsboro')\n",
    "    \n",
    "    plt.rcParams['figure.figsize'] = (18,5)\n",
    "    \n",
    "    plt.xticks(x, rotation=80)\n",
    "    plt.legend(fontsize=15)\n",
    "    plt.xlabel(xLabel,fontsize=15)\n",
    "    plt.ylabel(yLabel,fontsize=15)\n",
    "    plt.title(title)\n",
    "    plt.grid(True, linestyle='--')\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função para gerar um gráfico X outro\n",
    "def generate_vs_graphic(x, y1, y2, label1, label2, color1, color2, xLabel, yLabel, title):\n",
    "      \n",
    "    plt.rcParams['figure.figsize'] = (18,5)\n",
    "    plt.plot(x,y1,color=color1, linestyle='solid', linewidth=2,label=label1)\n",
    "    plt.plot(x,y2,color=color2, linestyle='solid', linewidth=2,label=label2)\n",
    "\n",
    "    plt.xticks(x, rotation=80)\n",
    "    plt.legend(fontsize=15)\n",
    "    plt.xlabel(xLabel,fontsize=15)\n",
    "    plt.ylabel(yLabel,fontsize=15)\n",
    "    plt.title(title)\n",
    "    plt.grid(True, linestyle='--')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_tweets_tokens(texts):\n",
    "        \n",
    "    tokens = []\n",
    "    \n",
    "    hashtags_words = ['coronavíru','coronaviru','víru','viru','corona','coronavírus','coronavirus','virus','vírus','covid','covid19','covid-19', '19']\n",
    "    words = ['’','“','','…','``','...','\\'\\'','t','https','http','co','rt','pra','pro','vc','pq','q','p','contra','tudo','sobre','aí','outro','tá','vai','ser','estar','está','to']\n",
    "    stopwords = words + default_hashtags + hashtags_words + list(punctuation) + nltk.corpus.stopwords.words('portuguese')\n",
    "    \n",
    "    tweet_tokenizer = TweetTokenizer()\n",
    "    \n",
    "    for text in texts:        \n",
    "        words = tweet_tokenizer.tokenize(text)\n",
    "        pos = nltk.pos_tag(words)\n",
    "        for word in words:\n",
    "            word.encode(\"ascii\", errors=\"ignore\").decode()      \n",
    "            if word.lower() not in stopwords:\n",
    "                tokens.append(word.lower())\n",
    "   \n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Funções para geração de gráficos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_bar_from_tokens_freq(tokens_freq, max_res, color, x, y, title):\n",
    "    \n",
    "    if len(tokens_freq) > 0:           \n",
    "        df_words = pd.DataFrame(tokens_freq, columns=['column','total'])\n",
    "        df_words = df_words.sort_values(by = ['total'], ascending=[False])\n",
    "        df_words[:max_res].plot(kind='barh', x='column',y='total', figsize=(x, y), color=color, title=title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_max_phrases_from_interval(df, start, end, max_res):\n",
    "    \n",
    "    top_words = []    \n",
    "    df_query = df.loc[(df['score'] > start) & (df['score'] < end)]\n",
    "\n",
    "    phrases = list(df_query['text'])   \n",
    "    counter = collections.Counter(phrases)\n",
    "    \n",
    "    return list(counter.most_common(max_res))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_max_tokens_from_interval(df, start, end, max_tokens):\n",
    "    \n",
    "    top_words = []    \n",
    "    df_query = df.loc[(df['score'] > start) & (df['score'] < end)]\n",
    "\n",
    "    words = list(df_query['text'])\n",
    "    tokens = generate_tweets_tokens(words)    \n",
    "    counter = collections.Counter(tokens)\n",
    "    \n",
    "    return list(counter.most_common(max_tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_tokens_from_interval(df, start, end):\n",
    "    \n",
    "    df_query = df.loc[(df['score'] > start) & (df['score'] < end)]\n",
    "\n",
    "    words = list(df_query['text'])\n",
    "    tokens = generate_tweets_tokens(words)\n",
    "    \n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_cloud_from_tokens(tokens, color):\n",
    "\n",
    "    df_words = pd.DataFrame(tokens, columns=['word'])\n",
    "\n",
    "    df_freq = df_words['word'].value_counts(normalize = True)\n",
    "    wordcloud = WordCloud(background_color=color, max_words=100, normalize_plurals=False).generate_from_frequencies(df_freq.to_dict())\n",
    "\n",
    "    plt.imshow(wordcloud, interpolation='bilinear')\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_bar_from_tokens(tokens, max_res, color, x, y, title):\n",
    "\n",
    "    if len(tokens) > 0:\n",
    "        df_words = pd.DataFrame(tokens, columns=['column'])\n",
    "        df_words['column'].value_counts()[:max_res].plot(kind='barh', figsize=(x, y), color=color, title=title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_bar_from_filtered_tokens(tokens, max_res, word_filter, color, x, y, title):\n",
    "    \n",
    "    hashtags = [word for word in tokens if word_filter in word and word not in default_hashtags]\n",
    "    \n",
    "    if len(hashtags) > 0:\n",
    "        df_hashtags = pd.DataFrame(hashtags, columns = ['column'])\n",
    "        df_hashtags['column'].value_counts()[:max_res].plot(kind='barh', figsize=(x, y), color=color, title=title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Realizando o merge do dataframe de scores x dataframe de casos\n",
    "def merge_dfs(df_scores_city, df_cases_city):\n",
    "\n",
    "    # Padronizando as colunas de datas\n",
    "    df_scores_city = df_scores_city.rename(columns={'created_at':'date'})\n",
    "\n",
    "    # Convertendo as colunas de datas para o mesmo tipo de objeto\n",
    "    df_scores_city = df_scores_city.astype({'date': str})\n",
    "    df_cases_city = df_cases_city.astype({'date': str})\n",
    "\n",
    "    # Realizando merges para recuperar período de datas em comum\n",
    "    return pd.merge(df_scores_city, df_cases_city, on='date', how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_tokens(df, column):\n",
    "    \n",
    "    all_tokens = []\n",
    "\n",
    "    for index, row in df.iterrows():\n",
    "        tokens = row[column]\n",
    "        for token in tokens:\n",
    "            all_tokens.append(token)\n",
    "\n",
    "    return all_tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Funções para cálculos de correlações com casos de Covid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função para derivar novos atributos\n",
    "def create_attributes(df_merged):\n",
    "    \n",
    "    # Somando colunas new_confirmed + new_deaths (notícias ruins do dia)\n",
    "    df_merged['bad_news'] = df_merged['new_confirmed'] + df_merged['new_deaths']\n",
    "\n",
    "    # Somando colunas last_available_confirmed + last_available_deaths (notícias ruins totais)\n",
    "    df_merged['last_bad_news'] = df_merged['last_available_confirmed'] + df_merged['last_available_deaths']\n",
    "\n",
    "    # Calculando percentual de crescimento de score de sentimento em relação ao dia anterior\n",
    "    # df_merged = calculate_percent(df_merged, 'score_mean', 'score_mean_pct')\n",
    "\n",
    "    # Calculando percentual de crescimento diário de novos casos em relação ao dia anterior\n",
    "    df_merged = calculate_percent(df_merged, 'new_confirmed', 'new_confirmed_pct')\n",
    "\n",
    "    # Calculando percentual de crescimento diário de novas mortes em relação ao dia anterior\n",
    "    df_merged = calculate_percent(df_merged, 'new_deaths', 'new_deaths_pct')\n",
    "\n",
    "    # Calculando percentual de crescimento diário de novos casos em relação ao total\n",
    "    df_merged = calculate_percent(df_merged, 'last_available_confirmed', 'last_available_confirmed_pct')\n",
    "\n",
    "    # Calculando percentual de crescimento diário de novas mortes em relação ao total\n",
    "    df_merged = calculate_percent(df_merged, 'last_available_deaths', 'last_available_deaths_pct')\n",
    "\n",
    "    # Calculando percentual de crescimento diário de novas mortes por 100k habitantes em relação ao total\n",
    "    df_merged = calculate_percent(df_merged, 'last_available_confirmed_per_100k_inhabitants', 'last_available_confirmed_per_100k_inhabitants_pct')\n",
    "\n",
    "    # Calculando percentual de crescimento diário da taxa de mortalidade em relação ao total\n",
    "    df_merged = calculate_percent(df_merged, 'last_available_death_rate', 'last_available_death_rate_pct')\n",
    "\n",
    "    # Calculando percentual de crescimento de notícias ruins em relação ao dia anterior\n",
    "    df_merged = calculate_percent(df_merged, 'bad_news', 'bad_news_pct')\n",
    "\n",
    "    # Calculando percentual de crescimento de notícias ruins em relação ao total\n",
    "    df_merged = calculate_percent(df_merged, 'last_bad_news', 'last_bad_news_pct')\n",
    "    \n",
    "    return df_merged;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Cálculo do percentual de crescimento de um valor no tempo\n",
    "def calculate_percent(df, column, new_column):  \n",
    "    \n",
    "    values_list = []\n",
    "    \n",
    "    is_first = True\n",
    "    last_value = 0\n",
    "    \n",
    "    for (i, row) in df.iterrows():\n",
    "        if (is_first == True):\n",
    "            is_first = False\n",
    "            last_value = row[column]\n",
    "            values_list.append(0)\n",
    "        else:\n",
    "            try:\n",
    "                percent = 100 * (((row[column] - last_value))/last_value)\n",
    "                percent = round(percent, 2)\n",
    "                values_list.append(percent)\n",
    "                last_value = row[column]\n",
    "            except ZeroDivisionError:\n",
    "                values_list.append(0)\n",
    "                last_value = row[column]\n",
    "            \n",
    "    df[new_column] = pd.Series(values_list, index = df.index)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data(df_cases_city, df_scores_city):\n",
    "    \n",
    "    # Realizando o merge dos dataframes de média de scores x dataframe de casos\n",
    "    df_merged = merge_dfs(df_scores_city, df_cases_city)\n",
    "    #print(df_merged.shape[0])\n",
    "\n",
    "    # Criando atributos derivados\n",
    "    df_merged = create_attributes(df_merged)\n",
    "    \n",
    "    return df_merged"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
